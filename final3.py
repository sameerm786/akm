# -*- coding: utf-8 -*-
"""final3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KSH33twHARvqfrxMm69xqdJu_8xzSZ8
"""



# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
import math
import os
import itertools
from keras.utils import np_utils
from sklearn.preprocessing import Normalizer, scale
from sklearn.datasets import load_files
import tensorflow as tf
from tensorflow import keras
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from tensorflow.keras.utils import plot_model
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler
from tensorflow.keras.utils import to_categorical
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.pylab as pylab
import seaborn as sns
import missingno as msno
import IPython
from IPython.display import display
from PIL import Image

# %matplotlib inline
mpl.style.use( 'ggplot' )
plt.style.use('fivethirtyeight')
sns.set(context="notebook", palette="dark", style = 'whitegrid' , color_codes=True)

train_dir = '/content/drive/MyDrive/ml/ml full/train'
val_dir = '/content/drive/MyDrive/ml/ml full/train'
test_dir='/content/drive/MyDrive/ml/ml full/test'

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(
    rescale = 1. / 255, # rescaling
    rotation_range = 8, # randomly rotate images in the range (degrees, 0 to 180)
    zoom_range = 0.1, # Randomly zoom image 
    shear_range = 0.3, # shear angle in counter-clockwise direction in degrees  
    width_shift_range = 0.08, # randomly shift images horizontally (fraction of total width)
    height_shift_range = 0.08, # randomly shift images vertically (fraction of total height)
    vertical_flip = True, # randomly flip images
    horizontal_flip = True) # randomly flip images


test_datagen = ImageDataGenerator(rescale = 1. / 255)

# Flow training images in batches of 10 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size = (200, 200),
        batch_size = 10,
        class_mode = 'categorical')

# Flow validation images in batches of 10 using test_datagen generator
validation_generator = test_datagen.flow_from_directory(
        val_dir,
        target_size = (200, 200),
        batch_size = 10,
        class_mode = 'categorical')

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') > 0.98 ): # Stop training the model at 98% traning accuracy
            print("\nReached 98% accuracy so cancelling training!")
            self.model.stop_training = True

# Building a 2D ConvNet
# CNN is derived from the convolutional operator (dot product of 2 functions to produce a 3rd function)

model = Sequential() # Sequential Keras API which is a linear stack of layers

model.add(Conv2D(filters = 32, # The number of filters (Kernels) used with this layer
                 
                 kernel_size = (5, 5), # The dimensions of the feature map
                 
                 activation = "relu", # Activation function - Rectified Linear Unit (ReLU)
                 
                 strides = 1, # How much the window (feature map) shifts by in each of the dimensions
                 
                 padding = "same", # When stride = 1, output spatial shape is the same as input spatial shape
                 
                 # There are two conventions for shapes of images tensors: the channels-last convention 
                 # (used by TensorFlow) and the channels-first convention (used by Theano)." 
                 # Deep Learning with Python - François Chollet
                 data_format = "channels_last",
                 
                 input_shape = (200, 200, 3))) # Input image dimensions

model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

# Max Pooling reduces the spatial dimensions of the feature maps before the fully connected layers
model.add(MaxPooling2D(pool_size = (2, 2)))

model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model.add(MaxPooling2D(pool_size = (2, 2)))
    
model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model.add(MaxPooling2D(pool_size = (2, 2)))

# To help avoid overfitting we can add Dropout. 
# This randomly drops some percentage of neurons, and thus the weights become re-aligned
model.add(Dropout(0.1))

# Finally, we can add a flatten layer to map the input to a 1D vector
# We then add fully connected (dense) layers after some convolutional/pooling layers.

model.add(Flatten())
model.add(Dense(256, activation = "relu"))
model.add(Dropout(0.3))
model.add(Dense(128, activation = "relu"))
model.add(Dropout(0.3))
model.add(Dense(6, activation = "softmax")) # activation function for Multi-Class Classification

optimizer = Adam(lr = 0.00002)

# Compiling the model
model.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics = ["accuracy"])

callbacks = myCallback()
history = model.fit(train_generator,
        batch_size = 16,
        epochs = 10,
        validation_data = validation_generator,
        callbacks = [callbacks],
        verbose = 1, shuffle = True)

model1 = Sequential() # Sequential Keras API which is a linear stack of layers

model1.add(Conv2D(filters = 32, # The number of filters (Kernels) used with this layer
                 
                 kernel_size = (5, 5), # The dimensions of the feature map
                 
                 activation = "relu", # Activation function - Rectified Linear Unit (ReLU)
                 
                 strides = 1, # How much the window (feature map) shifts by in each of the dimensions
                 
                 padding = "same", # When stride = 1, output spatial shape is the same as input spatial shape
                 
                 # There are two conventions for shapes of images tensors: the channels-last convention 
                 # (used by TensorFlow) and the channels-first convention (used by Theano)." 
                 # Deep Learning with Python - François Chollet
                 data_format = "channels_last",
                 
                 input_shape = (200, 200, 3))) # Input image dimensions

model1.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

# Max Pooling reduces the spatial dimensions of the feature maps before the fully connected layers
model1.add(MaxPooling2D(pool_size = (2, 2)))

model1.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model1.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model1.add(MaxPooling2D(pool_size = (2, 2)))
    
model1.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model1.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = "relu", 
                 strides = 1, padding = "same", data_format = "channels_last"))

model1.add(MaxPooling2D(pool_size = (2, 2)))

# To help avoid overfitting we can add Dropout. 
# This randomly drops some percentage of neurons, and thus the weights become re-aligned
model.add(Dropout(0.1))

# Finally, we can add a flatten layer to map the input to a 1D vector
# We then add fully connected (dense) layers after some convolutional/pooling layers.

model1.add(Flatten())
model1.add(Dense(256, activation = "relu"))
model1.add(Dropout(0.3))
model1.add(Dense(128, activation = "relu"))
model1.add(Dropout(0.3))
model1.add(Dense(64, activation = "relu"))
model1.add(Dropout(0.3))
model1.add(Dense(6, activation = "softmax")) # activation function for Multi-Class Classification

optimizer = Adam(lr = 0.00002)

model1.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics = ["accuracy"])

callbacks = myCallback()
history1 = model1.fit(train_generator,
        batch_size = 16,
        epochs = 5,
        validation_data = validation_generator,
        callbacks = [callbacks],
        verbose = 1, shuffle = True)

test_dir = '/content/drive/MyDrive/ml/ml full/test'

def load_dataset(path):
    data = load_files(path)
    files = np.array(data['filenames'])
    targets = np.array(data['target'])
    target_labels = np.array(data['target_names'])
    return files,targets,target_labels
    
x_test, y_test,target_labels = load_dataset(test_dir)

no_of_classes = len(np.unique(y_test))
y_test = np_utils.to_categorical(y_test, no_of_classes)

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import array_to_img

def convert_image_to_array(files):
    images_as_array=[]
    for file in files:
        # Convert to Numpy Array
        images_as_array.append(img_to_array(load_img(file)))
    return images_as_array

x_test = np.array(convert_image_to_array(x_test))
print('Test set shape : ',x_test.shape)

x_test = x_test.astype('float32')/255

# Final results
results = model.evaluate(x_test, y_test, batch_size=128)
print("test loss, test acc:", results)

model.save('my_model')



plt.figure(figsize = (12, 6))
accuracy = history.history["accuracy"]
val_accuracy = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(len(accuracy))

plt.plot(epochs, accuracy, 'b', label = "Training accuracy")
plt.plot(epochs, val_accuracy, 'r', label = "Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure(figsize = (12, 6))
plt.plot(epochs, loss, 'b', label = "Training loss")
plt.plot(epochs, val_loss, 'r', label = "Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()

test_dir = '/content/drive/MyDrive/ml/ml full/test'

def load_dataset(path):
    data = load_files(path)
    files = np.array(data['filenames'])
    targets = np.array(data['target'])
    target_labels = np.array(data['target_names'])
    return files,targets,target_labels
    
x_test, y_test,target_labels = load_dataset(test_dir)

from google.colab import drive
drive.mount('/content/drive')

no_of_classes = len(np.unique(y_test))
y_test = np_utils.to_categorical(y_test, no_of_classes)

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import array_to_img
import numpy as np

def resize_images(images, target_size):
    resized_images = []
    for image in images:
        # Resize and convert to Numpy Array
        resized_image = img_to_array(array_to_img(image).resize(target_size))
        resized_images.append(resized_image)
    return np.array(resized_images)

target_size = (64, 64)
x_test_resized = resize_images(x_test, target_size)
x_test_resized = x_test_resized.astype('float32') / 255.0
y_pred = model.predict(x_test_resized)
pred_labels = np.argmax(y_pred, axis=1)

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.image import array_to_img
import numpy as np
def convert_images_to_arrays(files):
    images_as_array = []
    for file in files:
        # Convert to Numpy Array
        image = load_img(file)
        array = img_to_array(image)
        images_as_array.append(array)
    return images_as_array

x_test = np.array(convert_images_to_arrays(x_test))
print('Test set shape:', x_test.shape)
x_test = x_test.astype('float32') / 255.0
results = model.evaluate(x_test, y_test, batch_size=128)
print("Test loss, Test accuracy:", results)



model.save('my_model')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# from keras.preprocessing.image import array_to_img, img_to_array, load_img
# from keras.models import Sequential, load_model
# import tensorflow as tf
# from tensorflow import keras
# from PIL import Image
# import io
# 
# new_model = tf.keras.models.load_model("my_model")
# 
# # Define class names
# class_names = ['Crazing', 'Inclusion', 'Patches', 'Pitted Surface', 'Rolled-in Scale', 'Scratches']
# 
# # Function to convert image to grayscale if it is RGB
# def convert_to_grayscale(img):
#     if len(img.shape) == 3:
#         return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     return img
# 
# # Function to detect defects
# def detect_defects(img):
#     st.text(img.shape)
#     #img = convert_to_grayscale(img)
#     new_img = img.astype('float32')/255
#     if new_img is not None:
#         # Reshape input to match model's input shape
#         new_img = np.reshape(new_img, (1, new_img.shape[0], new_img.shape[1], -1))
#         st.text(new_img.shape)
#         # Make predictions
#         prediction = new_model.predict(new_img)
#         # Get the index of the class with the highest probability
#         predicted_class_index = np.argmax(prediction)
#         # Get the name of the predicted class
#         predicted_class_name = class_names[predicted_class_index]
#         return predicted_class_name
#     else:
#         return 'no image detected'
# 
# # Function to convert uploaded image to array and detect defects
# def convert_image_to_array(image_bytes):
#     # If image_bytes is already in bytes format, skip the bytearray() step
#     if isinstance(image_bytes, bytes):
#         img_array = np.asarray(bytearray(image_bytes), dtype=np.uint8)
#     else:
#         with open(image_bytes, 'rb') as f:
#             img_array = np.asarray(bytearray(f.read()), dtype=np.uint8)
#     
#     img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     img = cv2.resize(img, (200, 200))
#     return img
# 
# # Streamlit app
# def app():
#     st.title("Defect Detection App")
#     # File uploader
#     uploaded_file = st.file_uploader("Choose an image...", type=["bmp","jpg", "jpeg", "png"])
#     if uploaded_file is not None:
#         # Show uploaded image
#         img_bytes = uploaded_file.read()
#         img_format = uploaded_file.type.split('/')[1]
#         img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
#         st.image(img, caption="Uploaded Image", use_column_width=True)
#         # Detect defects
#         if st.button("Detect Defects"):
#             output = detect_defects(convert_image_to_array(img_bytes))
#             st.write(output)
#             st.success("Defects detected!")
# 
# app()

